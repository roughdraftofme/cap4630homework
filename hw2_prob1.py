# -*- coding: utf-8 -*-
"""hw2_prob1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11aoprOTjctHxmKaQ2Z_cC5Yf6htN8WQO

# Classification of MNIST digits with dense layers

## Loading the image data
"""

from keras.datasets import mnist
import matplotlib.pyplot as plt
import numpy as np

(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()

"""## Preparing the image data"""

train_images = train_images_original.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255

test_images = test_images_original.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255

"""## Preparing the labels

We need to categorically encode the labels.
"""

from keras.utils import to_categorical

train_labels = to_categorical(train_labels_original)
test_labels = to_categorical(test_labels_original)

"""## Setting up the hand-crafted features

### Number of Connected Components
"""

next_label = 2

def flood_fill_single_region(img, row, col, label):
    # Base Case: If row or col is out of image boundary return
    if row < 0 or col < 0 or row > 27 or col > 27:
        return

    if img[row][col] > 0:
        return

    
    if img[row][col] == 0:
        img[row][col] = label
    
        flood_fill_single_region(img, row - 1, col, label)
        flood_fill_single_region(img, row + 1, col, label)
        flood_fill_single_region(img, row, col - 1 , label)
        flood_fill_single_region(img, row, col + 1, label)
    
    global next_label 
    next_label = label + 1
    

def make_image_black_white(img):
    bw_img = np.copy(img)

    for row in range(28):
        for col in range(28):
            if bw_img[row][col] > 127:
                bw_img[row][col] = 1.0
            else:
                bw_img[row][col] = 0.0

    return bw_img

def number_regions(img):
    new_image = make_image_black_white(img) # Returns copy fixed
    global next_label
    next_label = 2 # Reset label when starting new region
    
    for row in range(28):
       for col in range(28):
           flood_fill_single_region(new_image, row, col, next_label)
    return (next_label - 2)

"""### Height & Width"""

def height(img):
    maxHeight = 0

    for col in range(28):
        min = 0
        max = 27

        # print("COL ", col)
        # print()
        # print()

        while max > min:
            if img[min][col] == 0:
                # print("Moving min :)")
                min += 1
            if img[max][col] == 0:
                # print("Moving max :)")
                max -= 1
            
            if img[min][col] > 0 and img[max][col] > 0:
                if (max - min) > maxHeight:
                    maxHeight = max - min
                break

    return maxHeight

def width(img):
    maxWidth = 0

    for row in range(28):
        min = 0
        max = 27

        while max > min:
            if img[row][min] == 0:
                min += 1
            if img[row][max] == 0:
                max -= 1
            
            if img[row][min] > 0 and img[row][max] > 0:
                if (max - min) > maxWidth:
                    maxWidth = max - min + 1
                break

    return maxWidth

"""### Concatenating the data"""

train_data = np.zeros((60000, 787))

for x in range(60000):
    # to see progress as it is running
    print("Image: ", x)
    new_feats = np.array([])
    new_feats = np.append(new_feats, number_regions(train_images_original[x]))
    new_feats = np.append(new_feats, height(train_images_original[x]))
    new_feats = np.append(new_feats, width(train_images_original[x]))

    train_data[x] = np.concatenate((train_images[x], new_feats))

train_data.shape

test_data = np.zeros((10000, 787))

for x in range(10000):
    # to see progress as it is running
    print("Image: ", x)
    new_feats = np.array([])
    new_feats = np.append(new_feats, number_regions(test_images_original[x]))
    new_feats = np.append(new_feats, height(test_images_original[x]))
    new_feats = np.append(new_feats, width(test_images_original[x]))

    test_data[x] = np.concatenate((test_images[x], new_feats))

test_data.shape

"""## The network architecture"""

from keras import models
from keras import layers

network = models.Sequential()
network.add(layers.Dense(10, activation='softmax', input_shape=(787,)))
network.summary()

"""## The compilation step"""

network.compile(optimizer='rmsprop',
                loss='categorical_crossentropy',
                metrics=['accuracy'])

"""## The training step"""

epochs = 10
history = network.fit(train_data, 
                      train_labels, 
                      epochs=epochs, 
                      batch_size=128, 
                      validation_data=(test_data, test_labels))

"""## Display the training/test loss/accuracy"""

history_dict = history.history
loss_values = history_dict['loss']
test_loss_values = history_dict['val_loss']
epochs_range = range(1, epochs + 1)

plt.plot(epochs_range, loss_values, 'bo', label='Training loss')
plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')
plt.title('Training and test loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc_values = history_dict['acc']
test_acc_values = history_dict['val_acc']

plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')
plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')
plt.title('Training and test accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()